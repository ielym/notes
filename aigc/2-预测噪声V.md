# 0 引用

来自于 [PROGRESSIVE DISTILLATION FOR FAST SAMPLING OF DIFFUSION MODELS](https://arxiv.org/pdf/2202.00512.pdf) 渐进式蒸馏论文。

# 1 预测速度V的代码

速度预测中，模型的输出不再是噪声预测 $\epsilon(x_t, t)$ ，而是速度 $v_t$ 。如 Diffusers代码中：

```python
if noise_scheduler.config.prediction_type == "epsilon":
	target = noise
elif noise_scheduler.config.prediction_type == "v_prediction":
	target = noise_scheduler.get_velocity(latents, noise, timesteps)
else:
	raise ValueError(f"Unknown prediction type {noise_scheduler.config.prediction_type}")
    
model_pred = unet(noisy_latents, timesteps, encoder_hidden_states).sample


if args.snr_gamma is None:
	loss = F.mse_loss(model_pred.float(), target.float(), reduction="mean")
```

其中主要涉及的地方包括：

- `noise_scheduler.get_velocity` 中速度 $v$ 的计算
- 速度 $v$ 的理解

# 2 背景知识

## 2.1  $q(x_{t-1}|x_t)$ 的分布

扩散模型加噪过程可以表示成：
$$
x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \bar{\epsilon}_0 \in N(\sqrt{\bar{\alpha}_t} x_0, (1 - \bar{\alpha}_t)I)
$$
也可以表示成：
$$
x_t = \sqrt{\alpha_t} x_0 + \sqrt{1 - \alpha_t} \epsilon \in N(\sqrt{\alpha_t} x_0, (1 - \alpha_t)I)
$$
无论哪种表示，加噪过程中 $p(x_{t+1}|x_t)$ 或 $p(x_{t+1}|x_0)$ 都是已知的。

---

而扩散模型的去噪过程 $p(x_{t-1}|x_t)$ 的分布未知，为了计算 $p(x_{t-1} | x_t)$ ：

- 根据贝叶斯公式 + 马尔科夫链的性质得到：
  $$
  q(x_{t-1}|x_t, x_0) = q(x_{t-1}|x_t) = \frac{q(x_{t-1}|x_0)q(x_t|x_{t-1},x_0)}{q(x_t|x_0)}
  
  \\ \sim \frac{
  N(x_{t-1}; \sqrt{\bar{\alpha}_{t-1}} x_{0} , 1 - \bar{\alpha}_{t-1}) 
  N(x_t; \sqrt{\alpha_t} x_{t-1}, 1 - \alpha_t)
  }
  {N(x_t; \sqrt{\bar{\alpha}_t} x_{0} , 1 - \bar{\alpha}_t)}
  $$
  其中：
  $$
  q(x_{t-1} | x_0) = 
  \sqrt{\bar{\alpha}_{t-1}} x_{0} 
  +
  \sqrt{1 - \bar{\alpha}_{t-1}} \bar{z}_{0}
  
  \sim
  
  N(\sqrt{\bar{\alpha}_{t-1}} x_{0} , 1 - \bar{\alpha}_{t-1})
  
  \\
  
  q(x_t|x_{t-1},x_0) = 
  \sqrt{\alpha_{t}} x_{t-1} 
  +
  \sqrt{1 - \alpha_{t}} z_{t-1}
  
  \sim
  
  N(\sqrt{\alpha_{t}} x_{t-1} , 1 - \alpha_{t})
  
  \\
  
  q(x_t|x_0) = 
  \sqrt{\bar{\alpha}_{t}} x_{0} 
  +
  \sqrt{1 - \bar{\alpha}_{t}} \bar{z}_{0}
  
  \sim
  
  N(\sqrt{\bar{\alpha}_{t}} x_{0}, 1 - \bar{\alpha}_{t})
  $$

- 由 $p(x_{t-1} | x_t)$ 此时是由右侧三项全都已知的高斯分布混合组成，因此根据高斯混合模型得到 $p(x_{t-1} | x_t)$ 的概率密度函数表达式：
  $$
  q(x_{t-1}|x_t,x_0) = \frac{q(x_{t-1} | x_0) q(x_t|x_{t-1},x_0)}{q(x_t|x_0)}
  
  \\
  = 
  \frac{\frac{1}{\sqrt{2\pi} \sqrt{1 - \bar{\alpha}_{t-1}}} \frac{1}{\sqrt{2\pi} \sqrt{1 - \alpha_{t}}}}{\frac{1}{\sqrt{2\pi} \sqrt{1 - \bar{\alpha}_{t}}}}
  
  Exp
  {(
  
  -\frac{1}{2}
  (\frac{(x_{t-1} - \sqrt{\bar{\alpha}_{t-1}} x_{0})^2}{(1 - \bar{\alpha}_{t-1})}
  +\frac{(x_t - \sqrt{\alpha_{t}} x_{t-1})^2}{(1 - \alpha_{t})}
  - \frac{(x_t - \sqrt{\bar{\alpha}_{t}} x_{0})^2}{(1 - \bar{\alpha}_{t})})
  )}
  $$

- 上面概率密度函数有些复杂，对其进行一下化简。**需要注意，我们的目标 $p(x_{t-1} | x_t)$ 此时是已经能够求出表达式了，就可以采样了，所以化简的目的不是为了求解 $p(x_{t-1} | x_t)$ ，而是为了化简复杂的式子，找到其均值方差，从而进行采样 。**对概率密度函数表达式进行化简

  - 由于当 $x_t$ 已知时，$t$ 也是已知的，所以 $\alpha_t, \alpha_{t-1}$ 也是已知的。在化简时，为了简单起见，可以令其等于 $M$ ：
    $$
    q(x_{t-1}|x_t,x_0) = \frac{q(x_{t-1} | x_0) q(x_t|x_{t-1},x_0)}{q(x_t|x_0)}
    
    \\
    =
    M
    \cdot
    Exp
    {(
    -\frac{1}{2}
    (\frac{(x_{t-1} - \sqrt{\bar{\alpha}_{t-1}} x_{0})^2}{(1 - \bar{\alpha}_{t-1})}
    +\frac{(x_t - \sqrt{\alpha_{t}} x_{t-1})^2}{(1 - \alpha_{t})}
    - \frac{(x_t - \sqrt{\bar{\alpha}_{t}} x_{0})^2}{(1 - \bar{\alpha}_{t})})
    )}
    
    \\
    \propto
    
    Exp
    {(
    -\frac{1}{2}
    (\frac{(x_{t-1} - \sqrt{\bar{\alpha}_{t-1}} x_{0})^2}{(1 - \bar{\alpha}_{t-1})}
    +\frac{(x_t - \sqrt{\alpha_{t}} x_{t-1})^2}{(1 - \alpha_{t})}
    - \frac{(x_t - \sqrt{\bar{\alpha}_{t}} x_{0})^2}{(1 - \bar{\alpha}_{t})})
    )}
    $$

  - 一通化简之后，可以得到：
    $$
    q(x_{t-1}|x_t,x_0) = \frac{q(x_{t-1} | x_0) q(x_t|x_{t-1},x_0)}{q(x_t|x_0)}
    
    \\
    \propto
    
    Exp(-\frac{1}{2} [[\frac{1}{(1 - \bar{\alpha}_{t-1})} + \frac{\alpha_t}{(1 - \alpha_{t})}] x_{t-1}^2
    -
    [\frac{2\sqrt{\bar{\alpha}_{t-1}} x_0}{(1 - \bar{\alpha}_{t-1})} + \frac{2 \sqrt{\alpha_{t}} x_t}{(1 - \alpha_{t})}] x_{t-1}
    + 
    C(x_0, x_t)])
    $$
    其中，由于 $x_0, x_t$ 是已知量，所以把其相关的项都放在 $C(x_0, x_t)$ 中作为常数项，仅保留未知项 $x_{t-1}$ 相关的项。

  - 对照高斯分布的展开形式：
    $$
    Exp(- \frac{(x - \mu)^2}{2\sigma^2}) = Exp(-\frac{1}{2} \frac{x^2 + \mu^2 -2x\mu}{\sigma^2})
    \\=
    Exp(
    -\frac{1}{2} 
    (
    \frac{1}{\sigma^2} x^2
    -
    \frac{2\mu}{\sigma^2} x
    +
    \frac{\mu^2}{\sigma^2}
    )
    )
    $$
    可知：
    $$
    \frac{1}{\sigma^2} = \frac{1}{(1 - \bar{\alpha}_{t-1})} + \frac{\alpha_t}{(1 - \alpha_{t})}
    $$

    $$
    \frac{2\mu}{\sigma^2} = \frac{2\sqrt{\bar{\alpha}_{t-1}} x_0}{(1 - \bar{\alpha}_{t-1})} + \frac{2 \sqrt{\alpha_{t}} x_t}{(1 - \alpha_{t})}
    $$

    $$
    \frac{\mu^2}{\sigma^2} = C(x_0, x_t)
    $$

    即：
    $$
    \sigma^2 = 
    \frac{(1-\alpha_t) (1 - \bar{\alpha}_{t-1})}{1 - \alpha_t \bar{\alpha}_{t-1}}
    = 
    \frac{(1-\alpha_t) (1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_{t}}
    $$

    
    $$
    \mu = \sigma^2 [\frac{\sqrt{\bar{\alpha}_{t-1}} x_0}{(1 - \bar{\alpha}_{t-1})} + \frac{\sqrt{\alpha_{t}} x_t}{(1 - \alpha_{t})}]
    \frac{(1-\alpha_t) (1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_{t}}
    [\frac{\sqrt{\bar{\alpha}_{t-1}}}{(1 - \bar{\alpha}_{t-1})}x_0 + \frac{\sqrt{\alpha_{t}}}{(1 - \alpha_{t})}x_t]
    
    \\=
    \frac{\sqrt{\bar{\alpha}_{t-1}} (1-\alpha_t)}{1 - \bar{\alpha}_{t}} x_0
    +
    \frac{\sqrt{\alpha_{t}} (1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_{t}} x_t
    $$

  - 可以看出：

    - $\sigma$ 中不含未知项，因此一旦 $t$ 确定，即 $\alpha_t$ 确定，方差也就确定了，不含随机性。

    - $\mu$ 中还有个 $x_0$ ，根据 $x_t = \sqrt{\bar{\alpha}_t} x_{0} + \sqrt{1 - \bar{\alpha}_t} \bar{z}_{0}$ ，也可以估计出来：
      $$
      x_0 = \frac{x_t - \sqrt{1 - \bar{\alpha}_t} \bar{z}_{0}}{\sqrt{\bar{\alpha}_t}}
      $$

  - 把 $x_0$ 代入 $\mu$ ，一通化简之后，得到最终的结论：
    $$
    \sigma^2 = 
    \frac{(1-\alpha_t) (1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_{t}}
    $$

    $$
    \mu 
    =
    \frac{1}{\sqrt{\alpha_{t}}}
    
    (x_t - \frac
    {(1-\alpha_t)}
    {\sqrt{1 -  \bar{\alpha}_{t}}}
    \bar{z}_{0})
    $$

    - 其中，$x_t$ 是上一时间步的结果，$x_T \in N(0, I)$ 。$\bar{z_0}$ 是从 $x_0$  加噪时的噪声，推理时用UNet预测。

  - 有了均值方差后，可以采样出 $x_{t-1}$ ：
    $$
    x_{t-1} = 
    
    \frac{1}{\sqrt{\alpha_{t}}}
    (x_t - \frac
    {(1-\alpha_t)}
    {\sqrt{1 -  \bar{\alpha}_{t}}}
    \bar{z}_{0})
    
    +
    
    \sigma z
    $$

  ## 2.2 损失计算

  $p(x_{t-1} | x_t)$ 推出来均值和方差之后：

  - 方差项中不涉及预测或未知的变量
  - 均值项中，有 $x_0$ 和 $x_t$ 

  对于均值中的未知项：

  -  推理时，$x_t$ 是从标准高斯噪声中采样出来的；$x_0$ 是根据 $x_t = \sqrt{\bar{\alpha}_t} x_{0} + \sqrt{1 - \bar{\alpha}_t} \bar{z}_{0}$ 计算出来的；其中 $\bar{z}_{0}$ 是网络 $\epsilon(x_t, t)$ 估计出来的
  - 训练时，$x_t$ 是从 $x_t = \sqrt{\bar{\alpha}_t} x_{0} + \sqrt{1 - \bar{\alpha}_t} \bar{z}_{0}$ 计算出来的；$x_0$ 是训练图像，$\bar{z}_{0}$ 是采样的标准高斯噪声。

  训练目标：

  - 在采样  $p(x_{t-1} | x_t)$ 时，如果能够知道真实的 $x_0$ 就好了，但是推理时不可能知道，所以才用了假 $x_0$ 。

  - 所以，训练和推理唯一的区别就是 $x_0$ 不同。

  - 根据真实 $x_0$ 和假 $x_0$ 得到的均值需要对齐，把对齐均值作为训练目标：

    - 方差不含随机性，因此训练和推理都是一样的

    - 两个不同的 $x_0$ 构成的均值和方差一起，组成了两个高斯分布

    - 对齐两个高斯分布，计算KL散度，最终得到：
      $$
      argmin_\theta KL(q(x_{t-1}|x_t, x_0)||p_\theta(x_{t-1}|x_t))
      \\=
      argmin_\theta \frac{1}{2\sigma_q^2(t)} [||\mu_\theta - \mu_q||^2_2]
      \\=
      argmin_\theta \frac{1}{2\sigma_q^2(t)} [||
      \frac
      {
      
      \sqrt{\alpha_t} (1 - \bar{\alpha}_{t-1})x_t
      + 
      \sqrt{\bar{\alpha}_{t-1}} (1 - \alpha_t) \hat{x_\theta}(x_t, t)
      
      }
      {1 - \bar{\alpha}_{t}}
      
      
      -
      
      
      \frac
      {
      
      \sqrt{\alpha_t} (1 - \bar{\alpha}_{t-1})x_t
      + 
      \sqrt{\bar{\alpha}_{t-1}} (1 - \alpha_t) x_0
      
      }
      {1 - \bar{\alpha}_{t}}
      ||^2_2]
      
      \\=
      
      argmin_\theta \frac{1}{2\sigma_q^2(t)} [||
      \frac
      {
      \sqrt{\bar{\alpha}_{t-1}} (1 - \alpha_t) \hat{x_\theta}(x_t, t)
      
      }
      {1 - \bar{\alpha}_{t}}
      
      
      -
      
      
      \frac
      {
      \sqrt{\bar{\alpha}_{t-1}} (1 - \alpha_t) x_0
      
      }
      {1 - \bar{\alpha}_{t}}
      ||^2_2]
      
      \\=
      
      argmin_\theta \frac{1}{2\sigma_q^2(t)} [||
      \frac
      {
      \sqrt{\bar{\alpha}_{t-1}} (1 - \alpha_t) 
      
      }
      {1 - \bar{\alpha}_{t}}
      (
      \hat{x_\theta}(x_t, t)
      -
      x_0
      )
      ||^2_2]
      
      \\=
      
      argmin_\theta \frac{1}{2\sigma_q^2(t)} 
      \frac
      { \bar{\alpha}_{t-1} (1 - \alpha_t)^2 }
      {(1 - \bar{\alpha}_{t})^2}
      [||
      
      (
      \hat{x_\theta}(x_t, t)
      -
      x_0
      )
      ||^2_2]
      $$

    其中，$\hat{x_\theta}(x_t, t)$ 就是假 $x_0$

  - 可以看出，对齐两个高斯分布，等价于真假 $x_0$ 的MSE损失

  ---

  - 此外，真假 $x_0$ 都替换成 $x_0 = \frac{x_t - \sqrt{1 - \bar{\alpha}_t} \bar{z}_{0}}{\sqrt{\bar{\alpha}_t}}$ ，其中 $x_t$ 训练时用的都是真的，只不过 $z$ 一个是真实的，一个是网络预测的，代入 $x_0$ 的损失中得到：
    $$
    argmin_\theta KL(q(x_{t-1}|x_t, x_0)||p_\theta(x_{t-1}|x_t))
    \\=
    argmin_\theta \frac{1}{2\sigma_q^2(t)} [||\mu_\theta - \mu_q||^2_2]
    \\=
    
    argmin_\theta \frac{1}{2\sigma_q^2(t)} [
    ||
    
    (
    \frac
    { 1 }
    {\sqrt{\alpha_t}} 
    x_t
    
    -
    
    \frac
    { 1 - \alpha_t  }
    {\sqrt{1 - \bar{\alpha}_t}\sqrt{\alpha}_t}
    \bar{z}_{\theta}(x_t, t)
    )
    
    -
    
    (\frac
    { 1 }
    {\sqrt{\alpha_t}} 
    x_t
    
    -
    
    \frac
    { 1 - \alpha_t  }
    {\sqrt{1 - \bar{\alpha}_t}\sqrt{\alpha}_t}
    \bar{z}_{0})
    ||^2_2]
    
    \\=
    
    argmin_\theta \frac{1}{2\sigma_q^2(t)} [
    ||
    
    
    \frac
    { 1 - \alpha_t  }
    {\sqrt{1 - \bar{\alpha}_t}\sqrt{\alpha}_t}
    \bar{z}_{0}
    
    -
    
    \frac
    { 1 - \alpha_t  }
    {\sqrt{1 - \bar{\alpha}_t}\sqrt{\alpha}_t}
    \bar{z}_{\theta}(x_t, t)
    
    ||^2_2]
    
    \\=
    
    argmin_\theta \frac{1}{2\sigma_q^2(t)} [
    ||
    
    
    \frac
    { 1 - \alpha_t  }
    {\sqrt{1 - \bar{\alpha}_t}\sqrt{\alpha}_t}
    (\bar{z}_{0} - \bar{z}_{\theta}(x_t, t))
    
    ||^2_2]
    
    \\=
    
    argmin_\theta \frac{1}{2\sigma_q^2(t)}
    \frac
    { 1 - \alpha_t  }
    {\sqrt{1 - \bar{\alpha}_t}\sqrt{\alpha}_t} [
    ||
    
    
    
    (\bar{z}_{0} - \bar{z}_{\theta}(x_t, t))
    
    ||^2_2]
    $$

  - 所以预测 $x_0$ 也等价于预测噪声。

  ## 3 渐进式蒸馏速度相关部分

  符号对照：
  
  - $\alpha_t = \sqrt{\bar{\alpha_t}}$
  - $\sigma_t^2 = 1 - \bar{\alpha}_t$
  - $z_t = x_t$
  - $x = x_0$
  -  $x_t = \sqrt{\bar{\alpha}_t} x_0  + \sqrt{(1 - \bar{\alpha}_t)} \epsilon \in N(x_t; \sqrt{\bar{\alpha}_t} x_0, (1 - \bar{\alpha}_t)I)$ ，在渐进式蒸馏中替换成 $x_t = \alpha_t x_0  + \sigma_t \epsilon \in N(x_t; \alpha_t x_0, \sigma_t^2 I)$ 。 --- 虽然本来均值方差都和 $\bar{\alpha}_t$ 有关，但在渐进式蒸馏中不要把 $\alpha_t$ 和 $\sigma_t$ 联系到一起，否则很容易乱。并且，目前为止的符号替换是很好理解的，后面就把均值方差当成两个变量，不要迷在 $\alpha, \bar{\alpha}$  了。
  
  ---
  
  在噪声预测损失中，简化并忽略前面的系数项，得到 $L_\theta = || \epsilon - \hat{\epsilon}_\theta (z_t) ||_2^2$ 。又因为 $z_t = \alpha_t x + \sigma \epsilon$ ，因此：
  $$
  \epsilon = \frac{z_t - \alpha_t x}{\sigma_t}
  $$
  所以，
  $$
  L_\theta = || \epsilon - \hat{\epsilon}_\theta (z_t) ||_2^2 
  \\=
  || \frac{z_t - \alpha_t x}{\sigma_t} - \frac{z_t - \alpha_t \hat{x}_\theta(z_t)}{\sigma_t} ||_2^2
  \\=
  \frac{\alpha_t^2}{\sigma_t^2} || \hat{x}_\theta(z_t) - x ||_2^2
  $$
  其中，$\hat{x}_\theta (z_t)$ 是假 $x_0$ 。上式表示，重建噪声可以等价替换成在 $x$ 空间重建。
  
  ---
  
  **定义对数信噪比 ：**
  $$
  \lambda_t = log [\alpha_t^2 / \sigma_t^2]
  $$
  
  ---
  
  ## 3.1 噪声/图像损失 在步数蒸馏训练中存在的问题
  
  上述预测噪声和预测 $x$ 的两种损失在训练原始（1000步）模型上能够有效work，但是这两种损失不适用于步数蒸馏。







由于 $x_t = \sqrt{\bar{\alpha}_t} x_0  + \sqrt{(1 - \bar{\alpha}_t)} \epsilon \in N(x_t; \sqrt{\bar{\alpha}_t} x_0, (1 - \bar{\alpha}_t)I)$ ，因此 $x_t$ 可以理解成是 $x_0$ 向量和 $\epsilon$ 向量的线性加权，且权重系数 $ (\sqrt{\bar{\alpha}_t} ^2 + \sqrt{(1 - \bar{\alpha}_t)}^2) = 1 $ 。整个过程如下图所示。

![image-20231213142834319](./imgs/2-预测噪声V/image-20231213142834319.png)

- 根据刚在信噪比中近似的SNR结论，可以看出 $\mu = \sqrt{\bar{\alpha}_t}$ ，$\sigma = \sqrt{1 - \bar{\alpha}_t}$  。对应到上图，蓝色向量的模长有 $\mu^2 + \sigma^2 = $