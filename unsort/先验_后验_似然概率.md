# 先验概率

- 百度百科定义：先验概率（prior probability）是指根据以往经验和分析得到的概率，如全概率公式，它往往作为"由因求果"问题中的"因"出现的概率。
- 维基百科定义: 在贝叶斯统计中，某一不确定量p的先验概率分布是在考虑"观测数据"前，能表达p不确定性的概率分布。

可以看到二者定义有一个共同点，即**先验概率是不依靠观测数据的概率分布，也就是与其他因素独立的分布**。所以可以用P(θ)表示。

# 后验概率

- 维基百科定义: 在贝叶斯统计中，一个随机事件或者一个不确定事件的后验概率是**在考虑和给出相关证据或数据后**所得到的条件概率。同样，后验概率分布是一个未知量（视为随机变量）基于试验和调查后得到的概率分布。

简单的理解就是这个概率需要机遇观测数据才能得到，例如我们需要对一个神经网络建模，我们需要基于给定的数据集X才能得到网络参数θ的分布，所以后验概率表示为P(θ|X)

# 似然概率

- 百度百科定义: 统计学中，似然函数是一种关于统计模型参数的函数。给定输出x时，关于参数θ的似然函数L(θ|x)（在数值上）等于给定参数θ后变量X的概率：L(θ|x)=P(X=x|θ)。
  维基百科定义: 在数理统计学中，似然函数是一种关于统计模型中的参数的函数，表示模型参数中的似然性。

似然概率很好理解，就是说我们现在有一堆数据，现在需要构建一组参数对这些数据建模，以使得模型能够尽可能地拟合这些数据。所以我们要做的就是从很多组参数中选出一组使得模型对数据的拟合程度最高，所以也常常说最大似然概率，即 (P(X|θ)。



# 总结

- 先验概率 $P(\theta)$
- 后验概率 $P(\theta | X)$
- 似然概率 $P(X | \theta)$ 

贝叶斯公式：
$$
P(\theta | X) = \frac{P(X|\theta) P(\theta)}{P(X)}
$$
